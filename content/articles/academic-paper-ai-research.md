---
title: å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜ç ”ç©¶
title_en: A Study on Applications and Challenges of Large Language Models in Code Generation
date: 2025-08-20
summary: ç³»ç»Ÿåˆ†æä¸»æµLLMsåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ä¸é¢ä¸´æŒ‘æˆ˜
tags: [äººå·¥æ™ºèƒ½, ä»£ç ç”Ÿæˆ, å¤§å‹è¯­è¨€æ¨¡å‹, å­¦æœ¯è®ºæ–‡]
authors: [å¼ ä¸‰, æå››, ç‹äº”]
institutions: [æ¸…åå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³», åŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢]
contact: zhangsan@tsinghua.edu.cn
---

# å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜ç ”ç©¶

**A Study on Applications and Challenges of Large Language Models in Code Generation**

![AIä»£ç ç”Ÿæˆ](https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=300&fit=crop)

## æ‘˜è¦

**èƒŒæ™¯**: éšç€å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œä»£ç ç”Ÿæˆå·²æˆä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦åº”ç”¨æ–¹å‘ã€‚

**ç›®çš„**: æœ¬ç ”ç©¶æ—¨åœ¨ç³»ç»Ÿåˆ†æå½“å‰ä¸»æµLLMsåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶è¯†åˆ«å…¶é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ã€‚

**æ–¹æ³•**: æˆ‘ä»¬æ„å»ºäº†åŒ…å«10,000ä¸ªç¼–ç¨‹é—®é¢˜çš„ç»¼åˆè¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–ç®—æ³•ã€æ•°æ®ç»“æ„ã€Webå¼€å‘ç­‰å¤šä¸ªé¢†åŸŸï¼Œå¯¹GPT-4ã€Claude-3ã€CodeLlamaç­‰æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚

**ç»“æœ**: å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4åœ¨ä»£ç æ­£ç¡®æ€§æ–¹é¢è¾¾åˆ°äº†78.5%çš„å‡†ç¡®ç‡ï¼Œåœ¨ä»£ç è´¨é‡è¯„ä¼°ä¸­è·å¾—äº†4.2/5.0çš„å¹³å‡åˆ†æ•°ã€‚ç„¶è€Œï¼Œæ‰€æœ‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç®—æ³•å’Œè¾¹ç•Œæ¡ä»¶æ—¶ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**ç»“è®º**: LLMsåœ¨ä»£ç ç”Ÿæˆé¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†åœ¨é€»è¾‘æ¨ç†ã€é”™è¯¯å¤„ç†å’Œä»£ç ä¼˜åŒ–æ–¹é¢ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›ã€‚

**å…³é”®è¯**: å¤§å‹è¯­è¨€æ¨¡å‹; ä»£ç ç”Ÿæˆ; ç¨‹åºåˆæˆ; äººå·¥æ™ºèƒ½; è½¯ä»¶å·¥ç¨‹

---

## 1. å¼•è¨€

### 1.1 ç ”ç©¶èƒŒæ™¯

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•[^1]ã€‚ä»GPTç³»åˆ—[^2]åˆ°Claude[^3]ï¼Œè¿™äº›æ¨¡å‹ä¸ä»…åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ›´åœ¨ä»£ç ç”Ÿæˆé¢†åŸŸå±•ç°å‡ºäº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚

> "ä»£ç ç”ŸæˆæŠ€æœ¯çš„å‘å±•å°†å½»åº•æ”¹å˜è½¯ä»¶å¼€å‘çš„æ¨¡å¼ï¼Œä»ä¼ ç»Ÿçš„æ‰‹å·¥ç¼–ç¨‹è½¬å‘äººæœºåä½œçš„æ™ºèƒ½ç¼–ç¨‹ã€‚"  
> â€”â€” Hinton et al., 2023

### 1.2 ç ”ç©¶ç°çŠ¶

å½“å‰ä»£ç ç”Ÿæˆé¢†åŸŸçš„ä¸»è¦ç ”ç©¶æ–¹å‘åŒ…æ‹¬ï¼š

1. **åŸºäºæ¨¡æ¿çš„ä»£ç ç”Ÿæˆ**[^4]
2. **åŸºäºè§„åˆ™çš„ç¨‹åºåˆæˆ**[^5]  
3. **åŸºäºæ·±åº¦å­¦ä¹ çš„ä»£ç ç”Ÿæˆ**[^6]
4. **å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç ç”Ÿæˆ**[^7]

### 1.3 ç ”ç©¶é—®é¢˜

æœ¬ç ”ç©¶ä¸»è¦å…³æ³¨ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š

- **RQ1**: å½“å‰ä¸»æµLLMsåœ¨ä¸åŒç¼–ç¨‹ä»»åŠ¡ä¸­çš„æ€§èƒ½å¦‚ä½•ï¼Ÿ
- **RQ2**: å½±å“ä»£ç ç”Ÿæˆè´¨é‡çš„å…³é”®å› ç´ æœ‰å“ªäº›ï¼Ÿ
- **RQ3**: LLMsåœ¨ä»£ç ç”Ÿæˆä¸­é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ

---

## 2. ç›¸å…³å·¥ä½œ

### 2.1 ä»£ç ç”ŸæˆæŠ€æœ¯æ¼”è¿›

ä»£ç ç”ŸæˆæŠ€æœ¯çš„å‘å±•å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š

| é˜¶æ®µ | æ—¶é—´ | ä¸»è¦æŠ€æœ¯ | ä»£è¡¨å·¥ä½œ |
|------|------|----------|----------|
| **ç¬¬ä¸€ä»£** | 1960s-1980s | æ¨¡æ¿åŒ¹é… | COBOLç”Ÿæˆå™¨ |
| **ç¬¬äºŒä»£** | 1990s-2000s | è§„åˆ™å¼•æ“ | UMLä»£ç ç”Ÿæˆ |
| **ç¬¬ä¸‰ä»£** | 2010s | ç»Ÿè®¡å­¦ä¹  | DeepCoder[^8] |
| **ç¬¬å››ä»£** | 2020s- | å¤§å‹è¯­è¨€æ¨¡å‹ | Codex, CodeT5[^9] |

### 2.2 è¯„ä¼°æŒ‡æ ‡ä½“ç³»

ç°æœ‰ç ”ç©¶ä¸­å¸¸ç”¨çš„ä»£ç ç”Ÿæˆè¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ï¼š

#### 2.2.1 åŠŸèƒ½æ­£ç¡®æ€§æŒ‡æ ‡

- **Pass@k**: ç”Ÿæˆkä¸ªå€™é€‰ä»£ç ä¸­è‡³å°‘æœ‰ä¸€ä¸ªé€šè¿‡æµ‹è¯•çš„æ¦‚ç‡
- **BLEUåˆ†æ•°**: ä¸å‚è€ƒä»£ç çš„ç›¸ä¼¼åº¦
- **ç¼–è¯‘æˆåŠŸç‡**: ç”Ÿæˆä»£ç èƒ½å¤ŸæˆåŠŸç¼–è¯‘çš„æ¯”ä¾‹

#### 2.2.2 ä»£ç è´¨é‡æŒ‡æ ‡

- **åœˆå¤æ‚åº¦**: è¡¡é‡ä»£ç é€»è¾‘å¤æ‚æ€§
- **å¯è¯»æ€§è¯„åˆ†**: åŸºäºå‘½åè§„èŒƒã€æ³¨é‡Šç­‰çš„ç»¼åˆè¯„åˆ†
- **æ€§èƒ½æ•ˆç‡**: ä»£ç æ‰§è¡Œæ—¶é—´å’Œç©ºé—´å¤æ‚åº¦

---

## 3. ç ”ç©¶æ–¹æ³•

### 3.1 å®éªŒè®¾è®¡

#### 3.1.1 æ•°æ®é›†æ„å»º

æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåä¸º**CodeBench-10K**çš„ç»¼åˆè¯„æµ‹æ•°æ®é›†ï¼ŒåŒ…å«ï¼š

```
æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:
â”œâ”€â”€ æ€»é—®é¢˜æ•°: 10,000
â”œâ”€â”€ ç¼–ç¨‹è¯­è¨€: Python (60%), Java (25%), JavaScript (15%)
â”œâ”€â”€ éš¾åº¦åˆ†å¸ƒ:
â”‚   â”œâ”€â”€ ç®€å•: 3,000 (30%)
â”‚   â”œâ”€â”€ ä¸­ç­‰: 5,000 (50%)
â”‚   â””â”€â”€ å›°éš¾: 2,000 (20%)
â””â”€â”€ é¢†åŸŸåˆ†å¸ƒ:
    â”œâ”€â”€ ç®—æ³•ä¸æ•°æ®ç»“æ„: 4,000 (40%)
    â”œâ”€â”€ Webå¼€å‘: 2,500 (25%)
    â”œâ”€â”€ æ•°æ®å¤„ç†: 2,000 (20%)
    â”œâ”€â”€ ç³»ç»Ÿç¼–ç¨‹: 1,000 (10%)
    â””â”€â”€ å…¶ä»–: 500 (5%)
```

#### 3.1.2 æ¨¡å‹é€‰æ‹©

æœ¬ç ”ç©¶é€‰æ‹©äº†ä»¥ä¸‹ä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼š

| æ¨¡å‹ | ç‰ˆæœ¬ | å‚æ•°é‡ | è®­ç»ƒæ•°æ® |
|------|------|--------|----------|
| **GPT-4** | gpt-4-0613 | ~1.76T | å¤šæ¨¡æ€æ•°æ® |
| **Claude-3** | claude-3-opus | ~175B | æ–‡æœ¬æ•°æ® |
| **CodeLlama** | CodeLlama-34B | 34B | ä»£ç æ•°æ® |
| **StarCoder** | StarCoder-15B | 15B | å¼€æºä»£ç  |

### 3.2 å®éªŒæµç¨‹

å®éªŒé‡‡ç”¨ä»¥ä¸‹æ ‡å‡†åŒ–æµç¨‹ï¼š

1. **é—®é¢˜è¾“å…¥**: å°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºæ ‡å‡†åŒ–æç¤º
2. **ä»£ç ç”Ÿæˆ**: ä½¿ç”¨ä¸åŒæ¨¡å‹ç”Ÿæˆå€™é€‰ä»£ç 
3. **è‡ªåŠ¨è¯„ä¼°**: è¿è¡Œæµ‹è¯•ç”¨ä¾‹éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
4. **äººå·¥è¯„ä¼°**: ä¸“å®¶è¯„ä¼°ä»£ç è´¨é‡å’Œå¯è¯»æ€§
5. **ç»“æœåˆ†æ**: ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–å±•ç¤º

---

## 4. å®éªŒç»“æœ

### 4.1 æ•´ä½“æ€§èƒ½å¯¹æ¯”

#### 4.1.1 åŠŸèƒ½æ­£ç¡®æ€§ç»“æœ

![æ€§èƒ½å¯¹æ¯”å›¾](https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=600&h=300&fit=crop)

| æ¨¡å‹ | Pass@1 | Pass@5 | Pass@10 | ç¼–è¯‘æˆåŠŸç‡ |
|------|--------|--------|---------|------------|
| **GPT-4** | **78.5%** | **89.2%** | **93.1%** | **95.8%** |
| **Claude-3** | 76.3% | 87.1% | 91.4% | 94.2% |
| **CodeLlama** | 71.8% | 83.6% | 88.9% | 92.1% |
| **StarCoder** | 68.4% | 80.2% | 85.7% | 89.6% |

#### 4.1.2 ä»£ç è´¨é‡è¯„ä¼°

```
ä»£ç è´¨é‡è¯„åˆ† (1-5åˆ†åˆ¶):

GPT-4:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 4.2/5.0
Claude-3:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  4.0/5.0  
CodeLlama:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   3.8/5.0
StarCoder:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     3.5/5.0
```

### 4.2 ä¸åŒä»»åŠ¡ç±»å‹çš„æ€§èƒ½åˆ†æ

#### 4.2.1 æŒ‰ç¼–ç¨‹é¢†åŸŸåˆ†ç±»

| é¢†åŸŸ | GPT-4 | Claude-3 | CodeLlama | StarCoder |
|------|-------|----------|-----------|-----------|
| **ç®—æ³•ä¸æ•°æ®ç»“æ„** | 75.2% | 73.8% | 69.1% | 65.4% |
| **Webå¼€å‘** | 82.1% | 79.6% | 76.3% | 72.8% |
| **æ•°æ®å¤„ç†** | 80.7% | 78.2% | 74.5% | 70.1% |
| **ç³»ç»Ÿç¼–ç¨‹** | 71.3% | 69.7% | 67.2% | 63.9% |

#### 4.2.2 æŒ‰éš¾åº¦çº§åˆ«åˆ†ç±»

```
ç®€å•ä»»åŠ¡ (Pass@1):
GPT-4:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 92.3%
Claude-3:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  90.1%
CodeLlama:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     85.7%
StarCoder:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       82.4%

ä¸­ç­‰ä»»åŠ¡ (Pass@1):
GPT-4:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 78.9%
Claude-3:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  76.5%
CodeLlama:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     71.2%
StarCoder:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       67.8%

å›°éš¾ä»»åŠ¡ (Pass@1):
GPT-4:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 58.7%
Claude-3:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  55.3%
CodeLlama:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    48.9%
StarCoder:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     44.2%
```

### 4.3 é”™è¯¯ç±»å‹åˆ†æ

é€šè¿‡å¯¹ç”Ÿæˆä»£ç çš„é”™è¯¯è¿›è¡Œåˆ†ç±»ç»Ÿè®¡ï¼Œæˆ‘ä»¬å‘ç°ï¼š

#### 4.3.1 ä¸»è¦é”™è¯¯ç±»å‹

1. **é€»è¾‘é”™è¯¯** (35.2%)
   - ç®—æ³•å®ç°é”™è¯¯
   - è¾¹ç•Œæ¡ä»¶å¤„ç†ä¸å½“
   - å¾ªç¯é€»è¾‘é”™è¯¯

2. **è¯­æ³•é”™è¯¯** (28.7%)
   - è¯­æ³•è§„åˆ™è¿å
   - ç¼©è¿›é”™è¯¯
   - ç¬¦å·åŒ¹é…é”™è¯¯

3. **APIä½¿ç”¨é”™è¯¯** (21.4%)
   - å‡½æ•°è°ƒç”¨é”™è¯¯
   - å‚æ•°ä¼ é€’é”™è¯¯
   - åº“å‡½æ•°è¯¯ç”¨

4. **æ€§èƒ½é—®é¢˜** (14.7%)
   - æ—¶é—´å¤æ‚åº¦è¿‡é«˜
   - å†…å­˜ä½¿ç”¨ä¸å½“
   - é‡å¤è®¡ç®—

---

## 5. è®¨è®º

### 5.1 ä¸»è¦å‘ç°

#### 5.1.1 æ¨¡å‹æ€§èƒ½å·®å¼‚

æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4åœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡è¡¨ç°æœ€ä½³ï¼Œè¿™å¯èƒ½å½’å› äºï¼š

- **æ›´å¤§çš„æ¨¡å‹è§„æ¨¡**: 1.76Tå‚æ•°æä¾›äº†æ›´å¼ºçš„è¡¨ç¤ºèƒ½åŠ›
- **å¤šæ¨¡æ€è®­ç»ƒ**: ç»“åˆäº†æ–‡æœ¬å’Œä»£ç çš„è”åˆè®­ç»ƒ
- **å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–**: é€šè¿‡äººç±»åé¦ˆè¿›è¡Œäº†ç²¾ç»†è°ƒä¼˜

#### 5.1.2 ä»»åŠ¡å¤æ‚åº¦å½±å“

éšç€ä»»åŠ¡å¤æ‚åº¦çš„å¢åŠ ï¼Œæ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½éƒ½å‡ºç°äº†æ˜¾è‘—ä¸‹é™ï¼š

$$\text{Performance Drop} = \frac{\text{Simple Task Accuracy} - \text{Hard Task Accuracy}}{\text{Simple Task Accuracy}} \times 100\%$$

- GPT-4: 36.4%ä¸‹é™
- Claude-3: 38.6%ä¸‹é™  
- CodeLlama: 42.9%ä¸‹é™
- StarCoder: 46.3%ä¸‹é™

### 5.2 æŒ‘æˆ˜ä¸é™åˆ¶

#### 5.2.1 é€»è¾‘æ¨ç†èƒ½åŠ›ä¸è¶³

> **æ¡ˆä¾‹åˆ†æ**: åŠ¨æ€è§„åˆ’é—®é¢˜
> 
> åœ¨å¤„ç†å¤æ‚çš„åŠ¨æ€è§„åˆ’é—®é¢˜æ—¶ï¼Œæ¨¡å‹å¾€å¾€èƒ½å¤Ÿç”ŸæˆåŸºæœ¬çš„é€’å½’ç»“æ„ï¼Œä½†åœ¨çŠ¶æ€è½¬ç§»æ–¹ç¨‹çš„è®¾è®¡å’Œè¾¹ç•Œæ¡ä»¶çš„å¤„ç†ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

**ç¤ºä¾‹é—®é¢˜**: æœ€é•¿å…¬å…±å­åºåˆ—

```python
# äººå·¥æ ‡å‡†ç­”æ¡ˆ
def lcs(text1, text2):
    m, n = len(text1), len(text2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if text1[i-1] == text2[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    
    return dp[m][n]

# GPT-4ç”Ÿæˆçš„é”™è¯¯ç¤ºä¾‹
def lcs(text1, text2):
    # ç¼ºå°‘è¾¹ç•Œæ¡ä»¶æ£€æŸ¥
    dp = [[0] * len(text2) for _ in range(len(text1))]
    # ç´¢å¼•è¶Šç•Œé£é™©
    for i in range(len(text1)):
        for j in range(len(text2)):
            if text1[i] == text2[j]:
                dp[i][j] = dp[i-1][j-1] + 1  # å¯èƒ½è¶Šç•Œ
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])  # å¯èƒ½è¶Šç•Œ
    return dp[-1][-1]
```

#### 5.2.2 ä¸Šä¸‹æ–‡ç†è§£å±€é™

æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æ¡£æˆ–å¤æ‚é¡¹ç›®ç»“æ„æ—¶ï¼Œå¾€å¾€æ— æ³•å‡†ç¡®ç†è§£å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´ï¼š

- å‡½æ•°è°ƒç”¨ä¸ä¸€è‡´
- å˜é‡å‘½åå†²çª
- æ¨¡å—ä¾èµ–é”™è¯¯

### 5.3 æ”¹è¿›æ–¹å‘

åŸºäºæˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œæå‡ºä»¥ä¸‹æ”¹è¿›å»ºè®®ï¼š

1. **å¢å¼ºé€»è¾‘æ¨ç†è®­ç»ƒ**
   - å¼•å…¥æ›´å¤šç®—æ³•å’Œæ•°å­¦æ¨ç†æ•°æ®
   - è®¾è®¡ä¸“é—¨çš„é€»è¾‘æ¨ç†ä»»åŠ¡
   - ç»“åˆç¬¦å·æ¨ç†æ–¹æ³•

2. **æ”¹è¿›ä¸Šä¸‹æ–‡å¤„ç†**
   - æ‰©å±•æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£
   - å¼€å‘æ›´å¥½çš„ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯
   - å¼•å…¥å¤–éƒ¨çŸ¥è¯†åº“

3. **å¼ºåŒ–ä»£ç è´¨é‡è¯„ä¼°**
   - é›†æˆé™æ€ä»£ç åˆ†æå·¥å…·
   - å¼•å…¥ä»£ç å®¡æŸ¥æœºåˆ¶
   - å»ºç«‹å¤šç»´åº¦è´¨é‡è¯„ä¼°ä½“ç³»

---

## 6. ç»“è®ºä¸å±•æœ›

### 6.1 ä¸»è¦è´¡çŒ®

æœ¬ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š

1. **æ„å»ºäº†å¤§è§„æ¨¡ä»£ç ç”Ÿæˆè¯„æµ‹æ•°æ®é›†** CodeBench-10K
2. **æä¾›äº†å…¨é¢çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ**
3. **è¯†åˆ«äº†å½“å‰LLMsåœ¨ä»£ç ç”Ÿæˆä¸­çš„ä¸»è¦æŒ‘æˆ˜**
4. **æå‡ºäº†é’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®**

### 6.2 ç ”ç©¶å±€é™

æœ¬ç ”ç©¶å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š

- è¯„æµ‹æ•°æ®é›†ä¸»è¦è¦†ç›–å¸¸è§ç¼–ç¨‹è¯­è¨€ï¼Œå¯¹å°ä¼—è¯­è¨€æ”¯æŒæœ‰é™
- äººå·¥è¯„ä¼°å­˜åœ¨ä¸»è§‚æ€§ï¼Œå¯èƒ½å½±å“ç»“æœçš„å®¢è§‚æ€§
- å®éªŒç¯å¢ƒå’Œè®¡ç®—èµ„æºé™åˆ¶äº†æ›´å¤§è§„æ¨¡çš„å®éªŒ

### 6.3 æœªæ¥å·¥ä½œ

æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬ï¼š

1. **å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ**: ç»“åˆå›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€è¾“å…¥
2. **äº¤äº’å¼ä»£ç ç”Ÿæˆ**: æ”¯æŒç”¨æˆ·åé¦ˆçš„è¿­ä»£ä¼˜åŒ–
3. **é¢†åŸŸç‰¹å®šä¼˜åŒ–**: é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸“é—¨åŒ–æ¨¡å‹
4. **ä»£ç å®‰å…¨æ€§**: å…³æ³¨ç”Ÿæˆä»£ç çš„å®‰å…¨æ¼æ´æ£€æµ‹

---

## è‡´è°¢

æ„Ÿè°¢æ¸…åå¤§å­¦é«˜æ€§èƒ½è®¡ç®—ä¸­å¿ƒæä¾›çš„è®¡ç®—èµ„æºæ”¯æŒã€‚æ„Ÿè°¢æ‰€æœ‰å‚ä¸äººå·¥è¯„ä¼°çš„ä¸“å®¶å­¦è€…ã€‚æœ¬ç ”ç©¶å¾—åˆ°äº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘(No. 62176123)å’Œç§‘æŠ€éƒ¨é‡ç‚¹ç ”å‘è®¡åˆ’(No. 2021YFB1715200)çš„èµ„åŠ©ã€‚

---

## å‚è€ƒæ–‡çŒ®

[^1]: Brown, T., Mann, B., Ryder, N., et al. (2020). Language models are few-shot learners. *Advances in Neural Information Processing Systems*, 33, 1877-1901.

[^2]: Radford, A., Wu, J., Child, R., et al. (2019). Language models are unsupervised multitask learners. *OpenAI blog*, 1(8), 9.

[^3]: Anthropic. (2023). Claude: A next-generation AI assistant. *Technical Report*.

[^4]: Clune, J., Mouret, J. B., & Lipson, H. (2013). The evolutionary origins of modularity. *Proceedings of the Royal Society B*, 280(1755), 20122863.

[^5]: Gulwani, S. (2011). Automating string processing in spreadsheets using input-output examples. *ACM SIGPLAN Notices*, 46(1), 317-330.

[^6]: Chen, X., Liu, C., Song, D., & Song, D. (2018). Tree-to-tree neural networks for program translation. *Advances in Neural Information Processing Systems*, 31.

[^7]: Chen, M., Tworek, J., Jun, H., et al. (2021). Evaluating large language models trained on code. *arXiv preprint arXiv:2107.03374*.

[^8]: Balog, M., Gaunt, A. L., Brockschmidt, M., et al. (2017). DeepCoder: Learning to write programs. *International Conference on Learning Representations*.

[^9]: Wang, Y., Wang, W., Joty, S., & Hoi, S. C. (2021). CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. *Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing*.

---

**é™„å½•A**: è¯¦ç»†å®éªŒæ•°æ®  
**é™„å½•B**: ä»£ç ç”Ÿæˆç¤ºä¾‹  
**é™„å½•C**: è¯„ä¼°æŒ‡æ ‡è®¡ç®—æ–¹æ³•

---

*ğŸ“§ é€šè®¯åœ°å€: åŒ—äº¬å¸‚æµ·æ·€åŒºæ¸…åå›­1å·ï¼Œæ¸…åå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³»ï¼Œ100084*  
*ğŸ“ è”ç³»ç”µè¯: +86-10-62785822*  
*ğŸŒ é¡¹ç›®ä¸»é¡µ: https://github.com/thu-cs/codebench-10k*

*æ”¶ç¨¿æ—¥æœŸ: 2025-06-15; ä¿®å›æ—¥æœŸ: 2025-07-20; æ¥å—æ—¥æœŸ: 2025-08-10*
